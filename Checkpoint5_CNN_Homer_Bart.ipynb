{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "654f0e21"
      },
      "source": [
        "#**Redes Neurais Artificiais e Deep Learning**\n",
        "\n",
        "##**1. Definindo o problema**\n",
        "\n",
        "O objetivo deste projeto é desenvolver um **classificador de imagens** capaz de identificar automaticamente personagens específicos da série *Os Simpsons*, mais precisamente **Homer Simpson** e **Bart Simpson**.\n",
        "\n",
        "Para isso, será utilizada uma **Rede Neural Convolucional (CNN)** implementada com as bibliotecas **Keras** e **TensorFlow**. As CNNs são amplamente empregadas em tarefas de **visão computacional** devido à sua capacidade de extrair padrões visuais relevantes diretamente das imagens, dispensando o pré-processamento manual de características.\n",
        "\n",
        "---\n",
        "\n",
        "###**Como funciona a proposta?**\n",
        "\n",
        "- Alimentamos o modelo com um conjunto de **imagens rotuladas** de cada personagem (conjunto de treinamento);\n",
        "- Permitimos que a rede **aprenda** as características visuais que distinguem Homer e Bart;\n",
        "- Avaliamos sua performance em um **conjunto de imagens de teste** nunca vistas anteriormente.\n",
        "\n",
        "---\n",
        "\n",
        " O sistema resultante poderá ser utilizado como base para aplicações práticas, como:\n",
        "- Reconhecimento facial/cartoon;\n",
        "- Organização automática de imagens;\n",
        "- Ferramentas de entretenimento baseadas em visão computacional.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a106c36"
      },
      "source": [
        "## **2. Pré-processamento das imagens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31590cf6",
        "outputId": "55e5b377-f5df-456f-c2e1-0dd6de76c13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteúdo da pasta dataset_personagens: ['imagens', 'training_set', 'test_set', '.DS_Store']\n",
            "Found 196 images belonging to 2 classes.\n",
            "Found 73 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import zipfile  # Biblioteca para lidar com arquivos .zip\n",
        "import os  # Biblioteca para manipular o sistema de arquivos\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Utilizada para pré-processar imagens e aplicar data augmentation\n",
        "\n",
        "# Caminho do arquivo ZIP contendo o dataset de imagens\n",
        "zip_path = '/content/dataset_personagens.zip'\n",
        "\n",
        "# Descompacta o arquivo ZIP no diretório /content/\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# Lista os diretórios extraídos para garantir que tudo foi descompactado corretamente\n",
        "print(\"Conteúdo da pasta dataset_personagens:\", os.listdir('/content/dataset_personagens'))\n",
        "\n",
        "# Cria um gerador de imagens para o conjunto de treinamento com data augmentation\n",
        "gerador_treinamento = ImageDataGenerator(\n",
        "    rescale=1./255,            # Normaliza os pixels para o intervalo [0,1]\n",
        "    rotation_range=7,          # Rotaciona aleatoriamente as imagens em até 7 graus\n",
        "    horizontal_flip=True,      # Inverte horizontalmente algumas imagens\n",
        "    shear_range=0.2,           # Aplica transformação de cisalhamento (shear)\n",
        "    height_shift_range=0.07,   # Move verticalmente as imagens em até 7% da altura\n",
        "    zoom_range=0.2             # Aplica zoom aleatório em até 20%\n",
        ")\n",
        "\n",
        "# Cria um gerador para o conjunto de teste (sem data augmentation, apenas normalização)\n",
        "gerador_teste = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Caminhos das pastas com as imagens de treino e teste, já extraídas\n",
        "train_path = '/content/dataset_personagens/training_set'\n",
        "test_path = '/content/dataset_personagens/test_set'\n",
        "\n",
        "# Gera os lotes (batches) de imagens para o treinamento\n",
        "treinamento = gerador_treinamento.flow_from_directory(\n",
        "    train_path,                # Caminho da pasta de treinamento\n",
        "    target_size=(64, 64),      # Redimensiona todas as imagens para 64x64 pixels\n",
        "    batch_size=32,             # Número de imagens por lote\n",
        "    class_mode='categorical'   # Usa classificação multiclasse (vetores one-hot)\n",
        ")\n",
        "\n",
        "# Gera os lotes de imagens para o teste (sem data augmentation)\n",
        "teste = gerador_teste.flow_from_directory(\n",
        "    test_path,                 # Caminho da pasta de teste\n",
        "    target_size=(64, 64),      # Redimensiona para 64x64 (igual ao treino)\n",
        "    batch_size=32,             # Mesmo tamanho de lote\n",
        "    class_mode='categorical'   # Mesmo modo de classificação\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pré-processamento e Preparação do Dataset\n",
        "\n",
        "Nesta etapa do projeto, realizamos a **extração, organização e preparação das imagens** que serão utilizadas para treinar e avaliar o modelo de rede neural convolucional.\n",
        "\n",
        "Primeiramente, o código importa bibliotecas essenciais como `zipfile` e `os`, que permitem manipular arquivos compactados e diretórios no sistema. Em seguida, o dataset, que foi disponibilizado no formato `.zip`, é **descompactado diretamente no ambiente do Google Colab**. Isso garante que todas as imagens estejam acessíveis no formato de pastas esperadas pelas ferramentas de pré-processamento do Keras.\n",
        "\n",
        "Após a extração, utilizamos a classe `ImageDataGenerator` para configurar dois geradores de imagens:\n",
        "\n",
        "- O **gerador de treinamento** aplica técnicas de *data augmentation*, como **rotação**, **inversão horizontal**, **cisalhamento**, **deslocamento vertical** e **zoom**. Isso aumenta a diversidade do conjunto de dados e ajuda o modelo a generalizar melhor.\n",
        "- O **gerador de teste** realiza apenas a **normalização dos pixels**, redimensionando-os para o intervalo entre 0 e 1, mantendo a integridade dos dados para uma avaliação precisa do modelo.\n",
        "\n",
        "As imagens são organizadas em duas pastas principais:\n",
        "\n",
        "- `/training_set`: contém subpastas com imagens de treino de cada classe (*Bart* e *Homer*).\n",
        "- `/test_set`: contém subpastas com imagens de teste de cada classe.\n",
        "\n",
        "Os métodos `flow_from_directory()` são utilizados para **carregar automaticamente as imagens** dessas pastas, **rotulando-as com base na estrutura de diretórios**. As imagens são redimensionadas para **64x64 pixels**, agrupadas em lotes de **32 imagens** e preparadas para **classificação multiclasse** com vetores *one-hot*.\n",
        "\n",
        "Essa etapa garante que o modelo receba os dados no formato adequado, com pré-processamentos e aumentos aplicados corretamente, possibilitando um **treinamento mais robusto e eficaz**.\n"
      ],
      "metadata": {
        "id": "Cf5efCVQL1ID"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3612cae"
      },
      "source": [
        "## **3. Construção e explicação da arquitetura da CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "189fdb81",
        "outputId": "1d6a8543-6610-4535-d0cd-ca5a9f9e1dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 414ms/step - accuracy: 0.5546 - loss: 0.6823 - val_accuracy: 0.5753 - val_loss: 0.6492\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.6685 - loss: 0.5931 - val_accuracy: 0.8082 - val_loss: 0.5828\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.7403 - loss: 0.6197 - val_accuracy: 0.5890 - val_loss: 0.6265\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.6376 - loss: 0.5836 - val_accuracy: 0.7260 - val_loss: 0.4904\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.7455 - loss: 0.5058 - val_accuracy: 0.7534 - val_loss: 0.4683\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.7606 - loss: 0.4785 - val_accuracy: 0.8356 - val_loss: 0.3359\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8075 - loss: 0.4158 - val_accuracy: 0.7808 - val_loss: 0.4354\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.7372 - loss: 0.5088 - val_accuracy: 0.6164 - val_loss: 0.5781\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.7991 - loss: 0.4277 - val_accuracy: 0.9178 - val_loss: 0.2774\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.7910 - loss: 0.4338 - val_accuracy: 0.8493 - val_loss: 0.2744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e221fbd810>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Inicializa o modelo sequencial (camadas empilhadas linearmente)\n",
        "modelo = Sequential()\n",
        "\n",
        "# Primeira camada convolucional: 32 filtros 3x3, função de ativação ReLU e forma da imagem de entrada\n",
        "modelo.add(Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)))\n",
        "\n",
        "# Camada de pooling para reduzir a dimensionalidade (2x2)\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Segunda camada convolucional com 32 filtros\n",
        "modelo.add(Conv2D(32, (3,3), activation='relu'))\n",
        "\n",
        "# Pooling novamente para reduzir a dimensionalidade\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Terceira camada convolucional\n",
        "modelo.add(Conv2D(32, (3,3), activation='relu'))\n",
        "\n",
        "# Pooling final\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Achata a matriz de ativação 3D em um vetor 1D para a rede neural densa\n",
        "modelo.add(Flatten())\n",
        "\n",
        "# Camada totalmente conectada com 128 neurônios e ativação ReLU\n",
        "modelo.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Dropout para reduzir overfitting (20% dos neurônios desligados aleatoriamente)\n",
        "modelo.add(Dropout(0.2))\n",
        "\n",
        "# Camada de saída com 2 neurônios (2 classes: Bart e Homer) e softmax para classificação\n",
        "modelo.add(Dense(units=2, activation='softmax'))\n",
        "\n",
        "# Compila o modelo definindo otimizador, função de perda e métrica\n",
        "modelo.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Inicia o treinamento com 10 épocas, usando os dados de validação\n",
        "modelo.fit(treinamento, epochs=10, validation_data=teste)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Construção e Treinamento do Modelo com Rede Neural Convolucional (CNN)\n",
        "\n",
        "Nesta etapa, foi criada uma **rede neural convolucional (CNN)** utilizando a API Keras. A CNN é ideal para tarefas de visão computacional, pois consegue extrair automaticamente padrões visuais de imagens, como bordas, texturas e formas.\n",
        "\n",
        "O modelo foi construído com a classe `Sequential`, que permite adicionar camadas de forma linear. A arquitetura utilizada é composta por:\n",
        "\n",
        "- **3 camadas convolucionais** com 32 filtros cada e função de ativação `ReLU`, responsáveis por identificar padrões visuais nas imagens.\n",
        "- **3 camadas de MaxPooling** com tamanho 2x2, utilizadas para reduzir a dimensionalidade e evitar overfitting.\n",
        "- Uma camada `Flatten`, que achata os dados tridimensionais em um vetor unidimensional para ser processado pelas camadas densas.\n",
        "- Uma camada `Dense` com 128 neurônios e ativação `ReLU`, responsável pelo processamento das informações extraídas.\n",
        "- Um `Dropout` de 20%, que desliga aleatoriamente alguns neurônios durante o treinamento, ajudando a evitar o overfitting.\n",
        "- Uma camada de saída `Dense` com 2 neurônios e ativação `softmax`, pois estamos realizando uma **classificação multiclasse com duas categorias**: *Bart* e *Homer*.\n",
        "\n",
        "O modelo foi **compilado** com o otimizador `Adam`, uma escolha eficiente para ajuste automático da taxa de aprendizado, e com a função de perda `categorical_crossentropy`, adequada para classificações multiclasse com codificação one-hot.\n",
        "\n",
        "Por fim, o treinamento foi realizado por **10 épocas**, utilizando o conjunto de treinamento e validando a performance com os dados de teste a cada época.\n",
        "\n",
        "Com essa configuração, o modelo consegue aprender a distinguir os personagens com base em suas características visuais.\n"
      ],
      "metadata": {
        "id": "4uuzZ5AuNPUt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66797d2c"
      },
      "source": [
        "## **4. Avaliação do percentual de acerto do modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336e7a34",
        "outputId": "600d2303-37e2-4fe8-d220-6bac2a8624ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8387 - loss: 0.2934\n",
            "Acurácia no conjunto de teste: 84.93%\n"
          ]
        }
      ],
      "source": [
        "# Avalia a performance do modelo treinado no conjunto de teste\n",
        "loss, accuracy = modelo.evaluate(teste)\n",
        "\n",
        "# Exibe a acurácia final do modelo no conjunto de teste em formato percentual com duas casas decimais\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Avaliação do Modelo\n",
        "\n",
        "Após o treinamento, realizamos a **avaliação do modelo** utilizando o conjunto de teste, que contém imagens que **não foram vistas pelo modelo durante o treinamento**.\n",
        "\n",
        "A função `modelo.evaluate()` percorre o conjunto de teste e retorna duas métricas:\n",
        "\n",
        "- **Loss**: representa a perda (diferença entre a predição e o valor real);\n",
        "- **Accuracy**: indica a porcentagem de acertos do modelo.\n",
        "\n",
        "A acurácia é então exibida no console, formatada com duas casas decimais. Esse valor é fundamental para entender a capacidade de **generalização** do modelo — ou seja, como ele se comporta ao classificar dados novos e reais.\n",
        "\n",
        "Esse resultado mostra se o modelo realmente aprendeu os padrões dos personagens ou apenas memorizou os exemplos de treino.\n"
      ],
      "metadata": {
        "id": "y5OO7smcNwLT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7af54250"
      },
      "source": [
        "## **5. Teste do modelo com imagem externa**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "894f5fdb",
        "outputId": "186c2f3e-8c90-4bfd-ca6f-d3f59ebf7397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importa as bibliotecas necessárias\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Caminho da imagem a ser testada\n",
        "img_path = '/content/Homer_Simpson_2006.png'  # Pode ser alterado para homer1.png, por exemplo\n",
        "\n",
        "# Carrega a imagem redimensionando para 64x64 pixels (tamanho usado no treinamento)\n",
        "imagem_teste = image.load_img(img_path, target_size=(64, 64))\n",
        "\n",
        "# Converte a imagem carregada para um array NumPy\n",
        "imagem_teste_array = image.img_to_array(imagem_teste)\n",
        "\n",
        "# Adiciona uma dimensão extra ao array para simular um \"lote\" de uma imagem (batch size = 1)\n",
        "imagem_teste_array = np.expand_dims(imagem_teste_array, axis=0)\n",
        "\n",
        "# Normaliza os valores dos pixels (entre 0 e 1)\n",
        "imagem_teste_array /= 255\n",
        "\n",
        "# Realiza a predição com o modelo treinado\n",
        "resultado = modelo.predict(imagem_teste_array)\n",
        "\n",
        "# Recupera os nomes das classes, com base nos dados de treinamento\n",
        "classes = list(treinamento.class_indices.keys())\n",
        "\n",
        "# Exibe a imagem e o resultado da classificação\n",
        "plt.imshow(imagem_teste)                     # Mostra a imagem original\n",
        "plt.axis('off')                              # Remove os eixos\n",
        "plt.title(f'Predição: {classes[np.argmax(resultado)]}')  # Mostra o nome da classe prevista\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testando uma Imagem Nova\n",
        "\n",
        "Neste bloco, testamos o modelo com uma **imagem externa** (fora do conjunto de treinamento/teste) para verificar sua capacidade de **classificar corretamente personagens nunca vistos**.\n",
        "\n",
        "Os passos realizados são:\n",
        "\n",
        "1. **Carregamento da imagem** com tamanho (64x64 pixels), que é o mesmo utilizado na rede.\n",
        "2. **Pré-processamento**: a imagem é convertida em um array NumPy, expandida para simular um batch e normalizada (dividida por 255).\n",
        "3. **Predição**: a imagem é passada ao modelo para obter a probabilidade de cada classe.\n",
        "4. **Visualização**: o resultado é exibido junto com a imagem original, mostrando qual personagem foi identificado.\n",
        "\n",
        "Essa etapa é essencial para testar a **aplicabilidade real do modelo**, ou seja, se ele consegue identificar corretamente imagens individuais fornecidas pelo usuário.\n"
      ],
      "metadata": {
        "id": "ZIOiXH3_zFLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Conclusão**\n",
        "\n",
        "Neste projeto, foi desenvolvida e treinada uma **Rede Neural Convolucional (CNN)** utilizando as bibliotecas **Keras** e **TensorFlow**, com o objetivo de **classificar imagens dos personagens Homer e Bart Simpson**.\n",
        "\n",
        "---\n",
        "\n",
        "**Etapas do processo:**\n",
        "- Preparação e normalização das imagens;\n",
        "- Definição e construção da arquitetura da CNN;\n",
        "- Treinamento e avaliação do modelo com métricas de acurácia;\n",
        "- Testes com imagens externas ao dataset.\n",
        "\n",
        "---\n",
        "\n",
        "**Resultados:**  \n",
        "O modelo foi capaz de aprender a distinguir com precisão os dois personagens, demonstrando a eficácia das técnicas de **Visão Computacional** aplicadas à **classificação de imagens**.\n",
        "\n",
        "---\n",
        "\n",
        "**Considerações finais:**  \n",
        "Este projeto serviu como uma introdução prática ao uso de **Deep Learning para reconhecimento de padrões visuais**. A abordagem pode ser facilmente expandida para incluir outros personagens ou categorias, servindo como base para projetos mais avançados em visão computacional.\n",
        "\n"
      ],
      "metadata": {
        "id": "2f4z79uzzYdp"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}